{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tweedie Trilogy\n",
    "\n",
    "This is the notebook accompanying the Tweedie Trilogy blogpost series.\n",
    "\n",
    "As modelling tasks we take frequency and severity models for the French Motor Third-Party Liability Claims datasets [freMTPL2freq](https://www.openml.org/d/41214) and [freMTPL2sev](https://www.openml.org/d/41215).\n",
    "For more defails, we refer to\n",
    "[Case Study: French Motor Third-Party Liability Claims](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3164764) with [R code](https://github.com/JSchelldorfer/ActuarialDataScience/tree/master/1%20-%20French%20Motor%20Third-Party%20Liability%20Claims) as well as the 2 scikit-learn examples [Poisson regression and non-normal loss](https://scikit-learn.org/stable/auto_examples/linear_model/plot_poisson_regression_non_normal_loss.html#sphx-glr-auto-examples-linear-model-plot-poisson-regression-non-normal-loss-py) and [Tweedie regression on insurance claims](https://scikit-learn.org/stable/auto_examples/linear_model/plot_tweedie_regression_insurance_claims.html#sphx-glr-auto-examples-linear-model-plot-tweedie-regression-insurance-claims-py).\n",
    "\n",
    "## Table of Contents <a class=\"anchor\" id=\"toc\"></a>\n",
    "* [0 Load and Prepare Datasets](#0-load)\n",
    "* [1 Aggregation invariance](#1-aggregation)\n",
    "* [2 GLM offsets](#2-offsets)\n",
    "* [3 Full Tweedie Distribution](#3-full-tweedie)\n",
    "\n",
    "## 0 Load and Prepare Datasets from Openml.org <a class=\"anchor\" id=\"0-load\"></a>\n",
    "[back to table of contents](#toc)\n",
    "\n",
    "`freMTPL2freq` is a dataset with insurance policies per row. Every row has a policy id (`IDpol`), the time under insurance cover in years (`Exposure`), the number of claims (`ClaimNb`) and several features (`Area`, `VehPower`, `VehAge`, `DrivAge`, `BonusMalus`, `VehBrand`, `VehGas`, `Density`, `Region`).\n",
    "\n",
    "`freMTPL2sev` is a dataset with a single claim per row, the info to which policy it belongs (`IDpol`) and the ultimate claim amount (`ClaimAmount`).\n",
    "\n",
    "We will apply some modifications to the data itself:\n",
    "* We cut the number of claims to a maximum of 4, as is done in the case study paper. Reason: Data error suspected.\n",
    "* We cut the exposure to a maximum of 1, as is done in the case study paper. Reason: Data error suspected.\n",
    "* We cut the ClaimAmount at 100'000 per single claim (before aggregation per policy). Reason: For the largest claims, extreme value theory might apply. 100'000 is the 0.9984 quantile, claims larger than this limit account for 25% of the overall claim amount. This is a well known phenomenon for third-party liability.\n",
    "* We aggregate the total claim amounts per policy id and join them to freMTPL2freq.\n",
    "* With this aggregation step, we redefine ClaimNb as the number of claims with claim amount greater zero.\n",
    "\n",
    "[back to Table of Contents](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "from glum import GeneralizedLinearRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "from model_diagnostics.calibration import compute_bias\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "\n",
    "plt.ion()\n",
    "#set_config(transform_output=\"pandas\")\n",
    "\n",
    "# Glum emits a few of those related to newest pandas versions.\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "\n",
    "# GLM settings, we will use everywhere.\n",
    "glm_params = {\n",
    "    \"alpha\": 0,\n",
    "    \"drop_first\": True,\n",
    "    \"gradient_tol\": 1e-8,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_freq = fetch_openml(data_id=41214, as_frame=True, parser=\"auto\").data\n",
    "df_sev = fetch_openml(data_id=41215, as_frame=True, parser=\"auto\").data\n",
    "x_cat = [\"Area\",  \"VehBrand\", \"VehGas\", \"Region\"]  # categorical features\n",
    "x_num = [\"VehPower\", \"VehAge\", \"DrivAge\", \"BonusMalus\", \"Density\",]  # categorical features\n",
    "x_vars = x_cat + x_num\n",
    "\n",
    "# Correct dtype\n",
    "df_freq[\"IDpol\"] = df_freq[\"IDpol\"].astype(int)\n",
    "df_freq[\"VehGas\"] = df_freq.VehGas.astype(\"string\").str.replace(\"'\", \"\").astype(\"category\")\n",
    "\n",
    "# Correct for unreasonable observations (that might be data error)\n",
    "df_freq[\"ClaimNb\"] = df_freq['ClaimNb'].clip(upper=4)\n",
    "df_freq[\"Exposure\"] = df_freq['Exposure'].clip(upper=1)\n",
    "df_sev[\"ClaimAmount\"] = df_sev[\"ClaimAmount\"].clip(upper=100_000)\n",
    "\n",
    "# Sum ClaimAmount over identical IDpol (24950 unique IDpol).\n",
    "df_sev = df_sev.groupby(\"IDpol\", as_index=False).agg(\n",
    "    ClaimAmount=(\"ClaimAmount\", \"sum\"),\n",
    "    ClaimNb=(\"ClaimAmount\", \"count\"),\n",
    ")\n",
    "# Note that df_freq[\"ClaimNb\"].sum() = 36_056, but df_sev[\"ClaimNb\"].sum() = 26_639.\n",
    "# One reason for this inconsistency might be zero claims. We want to count claims only\n",
    "# with strictly positive claim amounts.\n",
    "# Also note that df_freq.duplicated(subset=\"IDpol\").sum() = 0, so no duplicate IDpol\n",
    "# in df_freq.\n",
    "\n",
    "# Join\n",
    "# We need pd.merge as df.join always uses index of left df.\n",
    "df = pd.merge(\n",
    "    left=df_freq,\n",
    "    right=df_sev,\n",
    "    how=\"left\",\n",
    "    on=\"IDpol\",\n",
    "    sort=False,\n",
    "    suffixes=(\"_FREQ\", \"\"),\n",
    ")\n",
    "df[\"ClaimNb\"].fillna(0, inplace=True)\n",
    "df[\"ClaimAmount\"].fillna(0, inplace=True)\n",
    "df.drop(columns=\"ClaimNb_FREQ\", inplace=True)\n",
    "df.set_index(\"IDpol\", inplace=True)\n",
    "# Now, we have df.ClaimNb.sum() = 26_444 claims left."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make this more interesting, we reduce the number of distrint values. We bin `Density` (1607 distinct values) and `BonusMalus` (115) into 5 values, 1 to 5.\n",
    "We also clip `DrivAge` (83) at 70 years and `VehAge` (78) at 50 years and also round down to the next multiple of 5.\n",
    "\n",
    "The point here is not to make very good GLMs with non-linear and interaction terms, but GLMs simple enough to stress the main points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Density\"] = pd.cut(df[\"Density\"], bins=5, labels=list(range(1, 6))).astype(int)\n",
    "df[\"BonusMalus\"] = pd.cut(df[\"BonusMalus\"], bins=5, labels=list(range(1, 6))).astype(int)\n",
    "df[\"DrivAge\"] = df[\"DrivAge\"].clip(upper=70)\n",
    "df[\"VehAge\"] = df[\"VehAge\"].clip(upper=50)\n",
    "df[\"DrivAge\"] = df[\"DrivAge\"] // 5 * 5\n",
    "df[\"VehAge\"] = df[\"VehAge\"] // 5 * 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 5, 12, 11)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Density.nunique(), df.BonusMalus.nunique(), df.DrivAge.nunique(), df.VehAge.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Exposure</th>\n",
       "      <th>Area</th>\n",
       "      <th>VehPower</th>\n",
       "      <th>VehAge</th>\n",
       "      <th>DrivAge</th>\n",
       "      <th>BonusMalus</th>\n",
       "      <th>VehBrand</th>\n",
       "      <th>VehGas</th>\n",
       "      <th>Density</th>\n",
       "      <th>Region</th>\n",
       "      <th>ClaimAmount</th>\n",
       "      <th>ClaimNb</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IDpol</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.10000</td>\n",
       "      <td>D</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>B12</td>\n",
       "      <td>Regular</td>\n",
       "      <td>1</td>\n",
       "      <td>R82</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.77000</td>\n",
       "      <td>D</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>B12</td>\n",
       "      <td>Regular</td>\n",
       "      <td>1</td>\n",
       "      <td>R82</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.75000</td>\n",
       "      <td>B</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>B12</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>1</td>\n",
       "      <td>R22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.09000</td>\n",
       "      <td>B</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>B12</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>1</td>\n",
       "      <td>R72</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.84000</td>\n",
       "      <td>B</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>B12</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>1</td>\n",
       "      <td>R72</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6114326</th>\n",
       "      <td>0.00274</td>\n",
       "      <td>E</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>B12</td>\n",
       "      <td>Regular</td>\n",
       "      <td>1</td>\n",
       "      <td>R93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6114327</th>\n",
       "      <td>0.00274</td>\n",
       "      <td>E</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>B12</td>\n",
       "      <td>Regular</td>\n",
       "      <td>2</td>\n",
       "      <td>R11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6114328</th>\n",
       "      <td>0.00274</td>\n",
       "      <td>D</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>B12</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>1</td>\n",
       "      <td>R82</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6114329</th>\n",
       "      <td>0.00274</td>\n",
       "      <td>B</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>B12</td>\n",
       "      <td>Regular</td>\n",
       "      <td>1</td>\n",
       "      <td>R26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6114330</th>\n",
       "      <td>0.00274</td>\n",
       "      <td>B</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>B12</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>1</td>\n",
       "      <td>R72</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>678013 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Exposure Area  VehPower  VehAge  DrivAge  BonusMalus VehBrand  \\\n",
       "IDpol                                                                    \n",
       "1         0.10000    D         5       0       55           1      B12   \n",
       "3         0.77000    D         5       0       55           1      B12   \n",
       "5         0.75000    B         6       0       50           1      B12   \n",
       "10        0.09000    B         7       0       45           1      B12   \n",
       "11        0.84000    B         7       0       45           1      B12   \n",
       "...           ...  ...       ...     ...      ...         ...      ...   \n",
       "6114326   0.00274    E         4       0       50           1      B12   \n",
       "6114327   0.00274    E         4       0       40           2      B12   \n",
       "6114328   0.00274    D         6       0       45           1      B12   \n",
       "6114329   0.00274    B         4       0       60           1      B12   \n",
       "6114330   0.00274    B         7       5       25           1      B12   \n",
       "\n",
       "          VehGas  Density Region  ClaimAmount  ClaimNb  \n",
       "IDpol                                                   \n",
       "1        Regular        1    R82          0.0      0.0  \n",
       "3        Regular        1    R82          0.0      0.0  \n",
       "5         Diesel        1    R22          0.0      0.0  \n",
       "10        Diesel        1    R72          0.0      0.0  \n",
       "11        Diesel        1    R72          0.0      0.0  \n",
       "...          ...      ...    ...          ...      ...  \n",
       "6114326  Regular        1    R93          0.0      0.0  \n",
       "6114327  Regular        2    R11          0.0      0.0  \n",
       "6114328   Diesel        1    R82          0.0      0.0  \n",
       "6114329  Regular        1    R26          0.0      0.0  \n",
       "6114330   Diesel        1    R72          0.0      0.0  \n",
       "\n",
       "[678013 rows x 12 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Aggregation Invariance <a class=\"anchor\" id=\"1-aggregation\"></a>\n",
    "[back to Table of Contents](#toc)\n",
    "\n",
    "When using scikit-learn, we would need a feature preprocessing pipeline, at least for the categorical variables. But we use glum instead, which can nativelely deal with those.\n",
    "\n",
    "### 1.1 GLMs on unaggregated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define target variables.\n",
    "y_freq = df[\"ClaimNb\"] / df[\"Exposure\"]\n",
    "y_sev = (df[\"ClaimAmount\"] / df[\"ClaimNb\"]).fillna(1e-10)  # Value does not matter as weights are set to zero.\n",
    "w_freq = df[\"Exposure\"]\n",
    "w_sev = df[\"ClaimNb\"].fillna(0)\n",
    "X = df[x_vars]\n",
    "\n",
    "# Fit GLMs, both poisson and gamma default to log link.\n",
    "glm_freq = GeneralizedLinearRegressor(\n",
    "    family=\"poisson\", **glm_params\n",
    ").fit(X, y_freq, sample_weight=w_freq)\n",
    "glm_sev = GeneralizedLinearRegressor(\n",
    "    family=\"gamma\", **glm_params\n",
    ").fit(X, y_sev, sample_weight=w_sev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total predicted number of claims = 26_444.00\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>bias_mean</th><th>bias_count</th><th>bias_weights</th><th>bias_stderr</th><th>p_value</th></tr><tr><td>f64</td><td>u32</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>1.9163e-13</td><td>678013</td><td>358360.105463</td><td>0.00061</td><td>1.0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1, 5)\n",
       "┌────────────┬────────────┬───────────────┬─────────────┬─────────┐\n",
       "│ bias_mean  ┆ bias_count ┆ bias_weights  ┆ bias_stderr ┆ p_value │\n",
       "│ ---        ┆ ---        ┆ ---           ┆ ---         ┆ ---     │\n",
       "│ f64        ┆ u32        ┆ f64           ┆ f64         ┆ f64     │\n",
       "╞════════════╪════════════╪═══════════════╪═════════════╪═════════╡\n",
       "│ 1.9163e-13 ┆ 678013     ┆ 358360.105463 ┆ 0.00061     ┆ 1.0     │\n",
       "└────────────┴────────────┴───────────────┴─────────────┴─────────┘"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\n",
    "    f\"Total predicted number of claims = \"\n",
    "    f\"{(w_freq * glm_freq.predict(X)).sum():_.2f}\"\n",
    ")\n",
    "compute_bias(y_obs=y_freq, y_pred=glm_freq.predict(X), weights=w_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total predicted claim amounts, given claim numbers = 49_309_687.30\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>bias_mean</th><th>bias_count</th><th>bias_weights</th><th>bias_stderr</th><th>p_value</th></tr><tr><td>f64</td><td>u32</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>0.283287</td><td>678013</td><td>26444.0</td><td>6.465931</td><td>0.965054</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1, 5)\n",
       "┌───────────┬────────────┬──────────────┬─────────────┬──────────┐\n",
       "│ bias_mean ┆ bias_count ┆ bias_weights ┆ bias_stderr ┆ p_value  │\n",
       "│ ---       ┆ ---        ┆ ---          ┆ ---         ┆ ---      │\n",
       "│ f64       ┆ u32        ┆ f64          ┆ f64         ┆ f64      │\n",
       "╞═══════════╪════════════╪══════════════╪═════════════╪══════════╡\n",
       "│ 0.283287  ┆ 678013     ┆ 26444.0      ┆ 6.465931    ┆ 0.965054 │\n",
       "└───────────┴────────────┴──────────────┴─────────────┴──────────┘"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Total predicted claim amounts, given claim numbers = {(w_sev * glm_sev.predict(X)).sum():_.2f}\")\n",
    "compute_bias(y_obs=y_sev, y_pred=glm_sev.predict(X), weights=w_sev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total predicted claim amounts = 49_319_656.72\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total predicted claim amounts = {(w_freq * glm_freq.predict(X) * glm_sev.predict(X)).sum():_.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total observed claim amounts = 49_302_196.05\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total observed claim amounts = {df['ClaimAmount'].sum():_.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the balance property is only valid for the Poisson GLM, not for the Gamma GLM, and therefore also not for their product predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 GLMs on aggregated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregation reduced number of rows from 678_013 to 133_413.\n"
     ]
    }
   ],
   "source": [
    "df_agg = df.groupby(x_vars, observed=True).sum().reset_index()\n",
    "print(\n",
    "    f\"Aggregation reduced number of rows from {df.shape[0]:_}\"\n",
    "    f\" to {df_agg.shape[0]:_}.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define target variables.\n",
    "y_agg_freq = df_agg[\"ClaimNb\"] / df_agg[\"Exposure\"]\n",
    "y_agg_sev = (df_agg[\"ClaimAmount\"] / df_agg[\"ClaimNb\"]).fillna(1e-10)  # Value does not matter as weights are zero.\n",
    "w_agg_freq = df_agg[\"Exposure\"]\n",
    "w_agg_sev = df_agg[\"ClaimNb\"].fillna(0)\n",
    "X_agg = df_agg[x_vars]\n",
    "\n",
    "# Fit GLMs.\n",
    "glm_agg_freq = GeneralizedLinearRegressor(\n",
    "    family=\"poisson\", **glm_params\n",
    ").fit(X_agg, y_agg_freq, sample_weight=w_agg_freq)\n",
    "glm_agg_sev = GeneralizedLinearRegressor(\n",
    "    family=\"gamma\", **glm_params\n",
    ").fit(X_agg, y_agg_sev, sample_weight=w_agg_sev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total predicted number of claims = 26_444.00\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>bias_mean</th><th>bias_count</th><th>bias_weights</th><th>bias_stderr</th><th>p_value</th></tr><tr><td>f64</td><td>u32</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>1.9162e-13</td><td>133413</td><td>358360.105463</td><td>0.000634</td><td>1.0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1, 5)\n",
       "┌────────────┬────────────┬───────────────┬─────────────┬─────────┐\n",
       "│ bias_mean  ┆ bias_count ┆ bias_weights  ┆ bias_stderr ┆ p_value │\n",
       "│ ---        ┆ ---        ┆ ---           ┆ ---         ┆ ---     │\n",
       "│ f64        ┆ u32        ┆ f64           ┆ f64         ┆ f64     │\n",
       "╞════════════╪════════════╪═══════════════╪═════════════╪═════════╡\n",
       "│ 1.9162e-13 ┆ 133413     ┆ 358360.105463 ┆ 0.000634    ┆ 1.0     │\n",
       "└────────────┴────────────┴───────────────┴─────────────┴─────────┘"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\n",
    "    f\"Total predicted number of claims = \"\n",
    "    f\"{(w_agg_freq * glm_agg_freq.predict(X_agg)).sum():_.2f}\"\n",
    ")\n",
    "compute_bias(y_obs=y_agg_freq, y_pred=glm_agg_freq.predict(X_agg), weights=w_agg_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total predicted claim amounts, given claim numbers = 49_309_687.30\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>bias_mean</th><th>bias_count</th><th>bias_weights</th><th>bias_stderr</th><th>p_value</th></tr><tr><td>f64</td><td>u32</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>0.283287</td><td>133413</td><td>26444.0</td><td>12.962511</td><td>0.982564</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1, 5)\n",
       "┌───────────┬────────────┬──────────────┬─────────────┬──────────┐\n",
       "│ bias_mean ┆ bias_count ┆ bias_weights ┆ bias_stderr ┆ p_value  │\n",
       "│ ---       ┆ ---        ┆ ---          ┆ ---         ┆ ---      │\n",
       "│ f64       ┆ u32        ┆ f64          ┆ f64         ┆ f64      │\n",
       "╞═══════════╪════════════╪══════════════╪═════════════╪══════════╡\n",
       "│ 0.283287  ┆ 133413     ┆ 26444.0      ┆ 12.962511   ┆ 0.982564 │\n",
       "└───────────┴────────────┴──────────────┴─────────────┴──────────┘"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Total predicted claim amounts, given claim numbers = {(w_agg_sev * glm_agg_sev.predict(X_agg)).sum():_.2f}\")\n",
    "compute_bias(y_obs=y_agg_sev, y_pred=glm_agg_sev.predict(X_agg), weights=w_agg_sev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total predicted claim amounts = 49_319_656.72\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total predicted claim amounts = {(w_agg_freq * glm_agg_freq.predict(X_agg) * glm_agg_sev.predict(X_agg)).sum():_.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total observed claim amounts = 49_302_196.05\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total observed claim amounts = {df_agg['ClaimAmount'].sum():_.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remark:** All total predicted numbers are the same, mean bias and bias weights are also the same.\n",
    "Even the total predicted claim amount, i.e. summing the product of frequency and severity model, returns the exact same number.\n",
    "Only the p-values and bias standard errors are different.\n",
    "This has to do with the estimation of weighted variances.\n",
    "But the difference is small.\n",
    "\n",
    "Finally, we show that even the GLM coefficients are the same (up to numerical precision)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intercept freq                  = -3.756437676421677\n",
      "intercept freq aggregated model = -3.756437676421675\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\n",
    "    f\"intercept freq{'':<18}= {glm_freq.intercept_}\\n\"\n",
    "    f\"intercept freq aggregated model = {glm_agg_freq.intercept_}\"\n",
    ")\n",
    "np.max(np.abs(glm_freq.coef_ - glm_agg_freq.coef_)) < 1e-13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This aggregation invariance property holds for all GLMs** (with EDF, without penalties)**, logistic regression included, and not just for Tweedie GLMs.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 GLM Offsets <a class=\"anchor\" id=\"2-offsets\"></a>\n",
    "[back to Table of Contents](#toc)\n",
    "\n",
    "### 2.1 Poisson GLM\n",
    "In this second part, we turn our attention to GLM offsets. We start with the Poisson frequency model where offsets and weights are equivalent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model counts N = w * freq with offsets (but without weights)\n",
    "N = w_freq * y_freq\n",
    "glm_offset_freq = GeneralizedLinearRegressor(\n",
    "    family=\"poisson\", **glm_params\n",
    ").fit(X, N, offset=np.log(w_freq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intercept freq        = -3.756437676421677\n",
      "intercept freq offset = -3.7564376764216725\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\n",
    "    f\"intercept freq{'':<8}= {glm_freq.intercept_}\\n\"\n",
    "    f\"intercept freq offset = {glm_offset_freq.intercept_}\"\n",
    ")\n",
    "np.max(np.abs(glm_freq.coef_ - glm_offset_freq.coef_)) < 1e-13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maximum absolute difference in predictions of number of claims:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(np.abs(w_freq * glm_freq.predict(X) - glm_offset_freq.predict(X, offset=np.log(w_freq))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Gamma GLM\n",
    "\n",
    "For all other GLMs, except the Poisson case, this equivalence **does not hold**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.8596235662471372e-15"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To make sure that the filter of w_sev > 0 does not change anything.\n",
    "w_gt_0 = w_sev > 0\n",
    "np.max(np.abs(\n",
    "    glm_sev.coef_ -\n",
    "    GeneralizedLinearRegressor(\n",
    "        family=\"gamma\", **glm_params\n",
    "    ).fit(\n",
    "        X[w_gt_0], y_sev[w_gt_0], sample_weight=w_sev[w_gt_0]\n",
    "    ).coef_\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model severity with weights (but without offsets)\n",
    "y_sev = (df[\"ClaimAmount\"] / df[\"ClaimNb\"])\n",
    "w_sev = df[\"ClaimNb\"].fillna(0)\n",
    "X = df[x_vars]\n",
    "# Filter out zero count (w_sev==0) rows\n",
    "w_gt_0 = w_sev > 0\n",
    "y_sev = y_sev[w_gt_0]\n",
    "X_sev = X[w_gt_0]\n",
    "w_sev = w_sev[w_gt_0]\n",
    "\n",
    "glm_sev = GeneralizedLinearRegressor(\n",
    "    family=\"gamma\", **glm_params\n",
    ").fit(X_sev, y_sev, sample_weight=w_sev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that the target is claim amount = w * sev.\n",
    "claim_amount = w_sev * y_sev\n",
    "glm_offset_sev = GeneralizedLinearRegressor(\n",
    "    family=\"gamma\", **glm_params\n",
    ").fit(X_sev, claim_amount, offset=np.log(w_sev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intercept sev        = 7.287909799461992\n",
      "intercept sev offset = 7.236827150674156\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.2119162919285421"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\n",
    "    f\"intercept sev{'':<8}= {glm_sev.intercept_}\\n\"\n",
    "    f\"intercept sev offset = {glm_offset_sev.intercept_}\"\n",
    ")\n",
    "np.max(np.abs(glm_sev.coef_ - glm_offset_sev.coef_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The deviations might seem small, but they are there and add up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total predicted claim amounts with weights 49_309_687.30\n",
      "Total predicted claim amounts offset       48_769_342.47\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"Total predicted claim amounts with weights \"\n",
    "    f\"{np.sum(w_sev * glm_sev.predict(X_sev)):_.2f}\"\n",
    ")\n",
    "print(\n",
    "    \"Total predicted claim amounts offset       \"\n",
    "    f\"{np.sum(glm_offset_sev.predict(X_sev, offset=np.log(w_sev))):_.2f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, it becomes evident that the two models are quite different."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
